{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vadim-Kolesnikov/U-net-Autoencoder/blob/main/translator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Импорт необходимых библитек"
      ],
      "metadata": {
        "id": "nkslkInZ3NMH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "from random import randint\n",
        "import unicodedata\n",
        "import re\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from keras.models import Model, load_model\n",
        "from keras.layers import Dense, Embedding, GRU, Input, Dense, Embedding, Bidirectional, Concatenate, Dropout, Dot\n",
        "from keras.optimizers import RMSprop, Adadelta, Adam\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from keras import utils\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.utils import plot_model\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import matplotlib.ticker as ticker\n",
        "%matplotlib inline\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "-_WDbtimajW8"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Загрузка данных"
      ],
      "metadata": {
        "id": "PJsqmmml3UVs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://storage.yandexcloud.net/academy.ai/rus-eng.zip\n",
        "!unzip -o rus-eng.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9Xjnf7xamZ0",
        "outputId": "c84db017-1609-401a-f325-c7ba74fc82dd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-10-02 10:52:28--  https://storage.yandexcloud.net/academy.ai/rus-eng.zip\n",
            "Resolving storage.yandexcloud.net (storage.yandexcloud.net)... 213.180.193.243, 2a02:6b8::1d9\n",
            "Connecting to storage.yandexcloud.net (storage.yandexcloud.net)|213.180.193.243|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 16305013 (16M) [application/x-zip-compressed]\n",
            "Saving to: ‘rus-eng.zip’\n",
            "\n",
            "rus-eng.zip         100%[===================>]  15.55M  9.83MB/s    in 1.6s    \n",
            "\n",
            "2024-10-02 10:52:31 (9.83 MB/s) - ‘rus-eng.zip’ saved [16305013/16305013]\n",
            "\n",
            "Archive:  rus-eng.zip\n",
            "  inflating: rus.txt                 \n",
            "  inflating: _about.txt              \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Основные переменные"
      ],
      "metadata": {
        "id": "u3EYDyac3aBv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 128\n",
        "EPOCHS = 1\n",
        "UNITS  = 1024\n",
        "EMBED_DIM = 256\n",
        "NUM_SAMPLES = 50000\n",
        "ATTENTION_UNITS = 10\n",
        "FILE_NAME = \"rus.txt\"\n",
        "SOS = '<start>'\n",
        "EOS = '<end>'"
      ],
      "metadata": {
        "id": "2BK5FHUTanx-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Считывание данных из файла и их преварительная обработка"
      ],
      "metadata": {
        "id": "PK2qbZV63e7L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_sentence(w):\n",
        "    w = re.sub(r\"([?.!,;:¿])\", r\" \\1 \", w)\n",
        "    w = re.sub(r'[\" \"]+', \" \", w)\n",
        "\n",
        "    w = re.sub(r\"[^a-zA-Zа-яёА-ЯЁ?'`.!,;:¿]+\", \" \", w)\n",
        "    w = w.rstrip().strip()\n",
        "\n",
        "    w = SOS + ' ' + w + ' ' + EOS\n",
        "    return w\n",
        "\n",
        "\n",
        "en_texts = []\n",
        "ru_texts = []\n",
        "\n",
        "with open(FILE_NAME, \"r\", encoding=\"utf-8\") as f:\n",
        "    lines = f.read().split(\"\\n\")\n",
        "\n",
        "for line in lines[: min(NUM_SAMPLES, len(lines) - 1)]:\n",
        "\n",
        "    en_text, ru_text, _ = line.split(\"\t\")\n",
        "\n",
        "    en_texts.append(preprocess_sentence(en_text))\n",
        "    ru_texts.append(preprocess_sentence(ru_text))\n",
        "\n",
        "print(\"Число используемых примеров:\", len(en_texts))\n",
        "print('Общее число примеров:', len(lines))\n",
        "random_index = randint(0, len(en_texts)-1)\n",
        "print(f'Пример текста на английском: {en_texts[random_index]}')\n",
        "print(f'Пример текста на русском: {ru_texts[random_index]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UthvIETQaxr0",
        "outputId": "66814117-18f9-4728-be61-fa99e31ffc68"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Число используемых примеров: 50000\n",
            "Общее число примеров: 496060\n",
            "Пример текста на английском: <start> Fire is dangerous . <end>\n",
            "Пример текста на русском: <start> Огонь опасен . <end>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Токенизация данных и формирование выборок"
      ],
      "metadata": {
        "id": "cdyfveMa3sbt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(text):\n",
        "    tokenizer = Tokenizer(filters='')\n",
        "    tokenizer.fit_on_texts(text)\n",
        "    seq = tokenizer.texts_to_sequences(text)\n",
        "    pseq = pad_sequences(seq, padding='post')\n",
        "    return pseq, tokenizer\n",
        "\n",
        "padded_en_texts, tokenizer_en = tokenize(en_texts)\n",
        "padded_ru_texts, tokenizer_ru = tokenize(ru_texts)\n",
        "\n",
        "max_length_en = padded_en_texts.shape[1]\n",
        "max_length_ru = padded_ru_texts.shape[1]\n",
        "\n",
        "en_train, en_test, ru_train, ru_test = train_test_split(padded_en_texts, padded_ru_texts, test_size=0.1)\n",
        "\n",
        "\n",
        "BUFFER_SIZE = len(en_train)\n",
        "STEPS_PER_EPOCH = len(en_train)//BATCH_SIZE\n",
        "VOCAB_EN_SIZE = len(tokenizer_en.word_index) + 1\n",
        "VOCAB_RU_SIZE = len(tokenizer_ru.word_index) + 1\n",
        "\n",
        "\n",
        "eng2rus_dataset = tf.data.Dataset.from_tensor_slices((en_train, ru_train)).shuffle(BUFFER_SIZE)\n",
        "eng2rus_dataset = eng2rus_dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "rus2eng_dataset = tf.data.Dataset.from_tensor_slices((ru_train, en_train)).shuffle(BUFFER_SIZE)\n",
        "rus2eng_dataset = rus2eng_dataset.batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "metadata": {
        "id": "RBT42o8_bddL"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Класс кодировщика"
      ],
      "metadata": {
        "id": "kPCcJC9x37jL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "\n",
        "  def __init__(self,\n",
        "               vocab_size,\n",
        "               embedding_dim,\n",
        "               enc_units,\n",
        "               batch_sz):\n",
        "\n",
        "    super(Encoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.enc_units = enc_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.enc_units, return_sequences=True, return_state=True, recurrent_initializer='glorot_uniform')\n",
        "\n",
        "  def call(self,\n",
        "           x,\n",
        "           hidden):\n",
        "\n",
        "    x = self.embedding(x)\n",
        "    output, state = self.gru(x, initial_state = hidden)\n",
        "    return output, state\n",
        "\n",
        "  def initialize_hidden_state(self):\n",
        "    return tf.zeros((self.batch_sz, self.enc_units))"
      ],
      "metadata": {
        "id": "714IWxqT4Gps"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Реализация механизма внимания Богданова"
      ],
      "metadata": {
        "id": "fEUCigWw3_qS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Attention(Model):\n",
        "\n",
        "  def __init__(self,\n",
        "               units):\n",
        "\n",
        "    super(Attention, self).__init__()\n",
        "    self.W1 = Dense(units)\n",
        "    self.W2 = Dense(units)\n",
        "    self.V =  Dense(1)\n",
        "\n",
        "  def call(self,\n",
        "           hidden_state,\n",
        "           values):\n",
        "\n",
        "    hidden_with_time_axis = tf.expand_dims(hidden_state, 1)\n",
        "    score = self.V(tf.nn.tanh(self.W1(values) + self.W2(hidden_with_time_axis)))\n",
        "    attention_weights = tf.nn.softmax(score, axis=1)\n",
        "    context_vector = attention_weights * values\n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "    return context_vector, attention_weights"
      ],
      "metadata": {
        "id": "YyX3MlVf4IWJ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Класс декодировщика"
      ],
      "metadata": {
        "id": "v0QbL57w4H2w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(Model):\n",
        "\n",
        "  def __init__(self,\n",
        "               vocab_size,\n",
        "               embedding_dim,\n",
        "               dec_units,\n",
        "               batch_sz):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.dec_units = dec_units\n",
        "    self.embedding = Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = GRU(self.dec_units, return_sequences=True, return_state=True, recurrent_initializer='glorot_uniform')\n",
        "    self.fc = Dense(vocab_size)\n",
        "    self.attention = Attention(ATTENTION_UNITS)\n",
        "\n",
        "  def call(self,\n",
        "           x,\n",
        "           hidden,\n",
        "           enc_output\n",
        "          ):\n",
        "    context_vector, attention_weights = self.attention(hidden, enc_output)\n",
        "\n",
        "    x = self.embedding(x)\n",
        "    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "    output, state = self.gru(x, initial_state = hidden)\n",
        "\n",
        "    output = tf.reshape(output, (-1, output.shape[2]))\n",
        "    x = self.fc(output)\n",
        "    return x, state, attention_weights"
      ],
      "metadata": {
        "id": "6x5LmUesb6Z4"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Класс автокодировщика с механизмом внимания"
      ],
      "metadata": {
        "id": "5GFTETa24SMh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MainModel():\n",
        "  def __init__(self, translate_type, vocab_inp_size, vocab_ans_size):\n",
        "\n",
        "    self.optimizer = tf.keras.optimizers.Adam()\n",
        "    self.encoder = Encoder(vocab_inp_size, EMBED_DIM, UNITS, BATCH_SIZE)\n",
        "    self.decoder = Decoder(vocab_ans_size, EMBED_DIM, UNITS, BATCH_SIZE)\n",
        "    self.checkpoint_dir = './training_checkpoints'\n",
        "    self.checkpoint_prefix = os.path.join(self.checkpoint_dir, \"ckpt\")\n",
        "    self.checkpoint = tf.train.Checkpoint(optimizer=self.optimizer,\n",
        "                                          encoder=self.encoder,\n",
        "                                          decoder=self.decoder)\n",
        "    self.translate_type = translate_type\n",
        "\n",
        "    if self.translate_type == 'eng2rus':\n",
        "\n",
        "      self.tokenizer_inp = tokenizer_en\n",
        "      self.tokenizer_out = tokenizer_ru\n",
        "\n",
        "      self.max_length_inp = max_length_en\n",
        "      self.max_length_out = max_length_ru\n",
        "\n",
        "    elif self.translate_type == 'rus2eng':\n",
        "      self.tokenizer_inp = tokenizer_ru\n",
        "      self.tokenizer_out = tokenizer_en\n",
        "\n",
        "      self.max_length_inp = max_length_ru\n",
        "      self.max_length_out = max_length_en\n",
        "\n",
        "  def loss_function(self, real, pred):\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')(real, pred)\n",
        "    mask = tf.cast(mask, dtype=loss.dtype)\n",
        "    loss *= mask\n",
        "\n",
        "    return tf.reduce_mean(loss)\n",
        "\n",
        "  @tf.function\n",
        "  def train_step(self, inp, targ, enc_hidden):\n",
        "    loss = 0\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "\n",
        "      enc_output, enc_hidden = self.encoder(inp, enc_hidden)\n",
        "\n",
        "      dec_hidden = enc_hidden\n",
        "\n",
        "      dec_input = tf.expand_dims([self.tokenizer_inp.word_index[SOS]] * BATCH_SIZE, 1)\n",
        "      for t in range(1, targ.shape[1]):\n",
        "        predictions, dec_hidden, _ = self.decoder(dec_input, dec_hidden, enc_output)\n",
        "        loss += self.loss_function(targ[:, t], predictions)\n",
        "        dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "\n",
        "\n",
        "    batch_loss = (loss / int(targ.shape[1]))\n",
        "    variables = self.encoder.trainable_variables + self.decoder.trainable_variables\n",
        "\n",
        "    gradients = tape.gradient(loss, variables)\n",
        "\n",
        "    self.optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "    return batch_loss\n",
        "\n",
        "  def train(self, train_data, epochs=EPOCHS):\n",
        "    for epoch in range(epochs):\n",
        "      start = time.time()\n",
        "\n",
        "      enc_hidden = self.encoder.initialize_hidden_state()\n",
        "      total_loss = 0\n",
        "\n",
        "      for (batch, (inp, targ)) in enumerate(train_data.take(STEPS_PER_EPOCH)):\n",
        "        batch_loss = self.train_step(inp, targ, enc_hidden)\n",
        "        total_loss += batch_loss\n",
        "\n",
        "      if (epoch + 1) % 5 == 0:\n",
        "        self.checkpoint.save(file_prefix = self.checkpoint_prefix)\n",
        "\n",
        "      print(f'Эпоха: {epoch + 1}  |  Потеря:  {(total_loss / STEPS_PER_EPOCH):.4f}  |  Время на эпоху: {time.time() - start} сек \\n' )\n",
        "\n",
        "  def evaluate(self, sentence):\n",
        "    sentence = preprocess_sentence(sentence)\n",
        "\n",
        "    words = sentence.split(' ')\n",
        "    inputs = list()\n",
        "\n",
        "    for word in words:\n",
        "\n",
        "        try:\n",
        "            inputs.append(self.tokenizer_inp.word_index[word])\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
        "                                                          maxlen=self.max_length_inp,\n",
        "                                                          padding='post')\n",
        "    inputs = tf.convert_to_tensor(inputs)\n",
        "    result = ''\n",
        "\n",
        "    hidden = [tf.zeros((1, UNITS))]\n",
        "    enc_out, enc_hidden = self.encoder(inputs, hidden)\n",
        "\n",
        "    dec_hidden = enc_hidden\n",
        "    dec_input = tf.expand_dims([self.tokenizer_out.word_index[SOS]], 0)\n",
        "\n",
        "    for t in range(self.max_length_out):\n",
        "      predictions, dec_hidden, attention_weights = self.decoder(dec_input,\n",
        "                                                          dec_hidden,\n",
        "                                                          enc_out)\n",
        "      attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "      predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "      result += self.tokenizer_out.index_word[predicted_id] + ' '\n",
        "\n",
        "      if self.tokenizer_out.index_word[predicted_id] == EOS:\n",
        "        return result, sentence\n",
        "\n",
        "      dec_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "    return result, sentence"
      ],
      "metadata": {
        "id": "K0G62ML94DRH"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Класс переводчика с английского на русский и обратно"
      ],
      "metadata": {
        "id": "M-qPB7ql4bYN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Translator():\n",
        "\n",
        "  def __init__(self):\n",
        "    self.eng2rus = MainModel('eng2rus', VOCAB_EN_SIZE, VOCAB_RU_SIZE)\n",
        "    self.rus2eng = MainModel('rus2eng', VOCAB_RU_SIZE, VOCAB_EN_SIZE)\n",
        "    self.is_trained = False\n",
        "\n",
        "  def train(self, eng2rus_dataset, rus2eng_dataset, epochs=EPOCHS):\n",
        "    self.eng2rus.train(eng2rus_dataset, epochs)\n",
        "    self.rus2eng.train(rus2eng_dataset, epochs)\n",
        "    self.is_trained = True\n",
        "\n",
        "  def translate(self, sentence, translate_type):\n",
        "    if self.is_trained:\n",
        "      if translate_type == 'eng2rus':\n",
        "        return self.eng2rus.evaluate(sentence)[0]\n",
        "      else:\n",
        "        return self.rus2eng.evaluate(sentence)[0]\n",
        "    else:\n",
        "      return 'Для начала модель необходимо обучить'\n"
      ],
      "metadata": {
        "id": "ifPEfjUIkR_u"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Обучение модели"
      ],
      "metadata": {
        "id": "I0cCRs0-8byN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "translator = Translator()\n",
        "translator.train(eng2rus_dataset, rus2eng_dataset, EPOCHS)"
      ],
      "metadata": {
        "id": "w8iklvhcsi5N",
        "outputId": "8695f70c-b9ed-49a6-b12d-97c220b8a956",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпоха: 1  |  Потеря:  1.8831  |  Время на эпоху: 207.05141639709473 сек \n",
            "\n",
            "Эпоха: 1  |  Потеря:  1.8606  |  Время на эпоху: 133.57495522499084 сек \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Демонстрация работы модели"
      ],
      "metadata": {
        "id": "epN48kc08fvb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def detokinize(vect, lng='eng'):\n",
        "  result = ''\n",
        "  for i in vect:\n",
        "    try:\n",
        "      if lng == 'eng':\n",
        "        result += tokenizer_en.index_word[i] + ' '\n",
        "      else:\n",
        "        result += tokenizer_ru.index_word[i] + ' '\n",
        "    except:\n",
        "      pass\n",
        "  return result"
      ],
      "metadata": {
        "id": "bcQd7bJ6V7JN"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_samples = 10\n",
        "dct = {'en': [], 'ru': [], 'en -> ru': [], 'ru -> en': []}\n",
        "for i in range(n_samples):\n",
        "\n",
        "  en = detokinize(en_test[i], lng='eng')\n",
        "  ru = detokinize(ru_test[i], lng='rus')\n",
        "  pred_en2ru = translator.translate(en, 'eng2rus')\n",
        "  pred_ru2en = translator.translate(ru, 'rus2eng')\n",
        "\n",
        "  dct['en'].append(en)\n",
        "  dct['ru'].append(ru)\n",
        "  dct['en -> ru'].append(pred_en2ru)\n",
        "  dct['ru -> en'].append(pred_ru2en)\n",
        "\n",
        "\n",
        "df = pd.DataFrame(dct)\n",
        "df"
      ],
      "metadata": {
        "id": "2o39IgLy85Dn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "8eb53a0b-9257-46dd-8411-e17f3efffa4a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                   en  \\\n",
              "0         <start> i fixed it . <end>    \n",
              "1    <start> i'm young , too . <end>    \n",
              "2       <start> what a sight ! <end>    \n",
              "3  <start> just take me home . <end>    \n",
              "4        <start> you need it . <end>    \n",
              "5    <start> tom wasn't rich . <end>    \n",
              "6   <start> that's not yours . <end>    \n",
              "7     <start> i like walking . <end>    \n",
              "8        <start> be prepared . <end>    \n",
              "9   <start> it should be fun . <end>    \n",
              "\n",
              "                                          ru  \\\n",
              "0              <start> я её починил . <end>    \n",
              "1            <start> я тоже молодой . <end>    \n",
              "2             <start> какое зрелище ! <end>    \n",
              "3  <start> просто отвези меня домой . <end>    \n",
              "4            <start> тебе это нужно . <end>    \n",
              "5          <start> том не был богат . <end>    \n",
              "6               <start> это не твоё . <end>    \n",
              "7       <start> мне нравится гулять . <end>    \n",
              "8             <start> будьте готовы ! <end>    \n",
              "9        <start> должно быть весело . <end>    \n",
              "\n",
              "                                            en -> ru  \\\n",
              "0                               я меня есть . <end>    \n",
              "1      я меня , что что что что что что что что что    \n",
              "2                                 ты ты это ? <end>    \n",
              "3     мы меня , что что что что что что что что что    \n",
              "4                               они не меня . <end>    \n",
              "5  ты не не не не что что что что пожалуйста . <e...   \n",
              "6                             это не не это . <end>    \n",
              "7   я меня есть что что что что что что что что что    \n",
              "8                                   они это . <end>    \n",
              "9        ты не не не что что что пожалуйста . <end>    \n",
              "\n",
              "                    ru -> en  \n",
              "0        i don't be . <end>   \n",
              "1   i was a bit shy . <end>   \n",
              "2        it's a bit . <end>   \n",
              "3     don't go , go . <end>   \n",
              "4       you must go . <end>   \n",
              "5  tom was very shy . <end>   \n",
              "6   it's not a liar . <end>   \n",
              "7        i love you . <end>   \n",
              "8     open the door . <end>   \n",
              "9   it's a bit good . <end>   "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5a4b673d-4577-41f2-8ff1-929ad5ad919f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>en</th>\n",
              "      <th>ru</th>\n",
              "      <th>en -&gt; ru</th>\n",
              "      <th>ru -&gt; en</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>&lt;start&gt; i fixed it . &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; я её починил . &lt;end&gt;</td>\n",
              "      <td>я меня есть . &lt;end&gt;</td>\n",
              "      <td>i don't be . &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>&lt;start&gt; i'm young , too . &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; я тоже молодой . &lt;end&gt;</td>\n",
              "      <td>я меня , что что что что что что что что что</td>\n",
              "      <td>i was a bit shy . &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>&lt;start&gt; what a sight ! &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; какое зрелище ! &lt;end&gt;</td>\n",
              "      <td>ты ты это ? &lt;end&gt;</td>\n",
              "      <td>it's a bit . &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>&lt;start&gt; just take me home . &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; просто отвези меня домой . &lt;end&gt;</td>\n",
              "      <td>мы меня , что что что что что что что что что</td>\n",
              "      <td>don't go , go . &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>&lt;start&gt; you need it . &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; тебе это нужно . &lt;end&gt;</td>\n",
              "      <td>они не меня . &lt;end&gt;</td>\n",
              "      <td>you must go . &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>&lt;start&gt; tom wasn't rich . &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; том не был богат . &lt;end&gt;</td>\n",
              "      <td>ты не не не не что что что что пожалуйста . &lt;e...</td>\n",
              "      <td>tom was very shy . &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>&lt;start&gt; that's not yours . &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; это не твоё . &lt;end&gt;</td>\n",
              "      <td>это не не это . &lt;end&gt;</td>\n",
              "      <td>it's not a liar . &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>&lt;start&gt; i like walking . &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; мне нравится гулять . &lt;end&gt;</td>\n",
              "      <td>я меня есть что что что что что что что что что</td>\n",
              "      <td>i love you . &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>&lt;start&gt; be prepared . &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; будьте готовы ! &lt;end&gt;</td>\n",
              "      <td>они это . &lt;end&gt;</td>\n",
              "      <td>open the door . &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>&lt;start&gt; it should be fun . &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; должно быть весело . &lt;end&gt;</td>\n",
              "      <td>ты не не не что что что пожалуйста . &lt;end&gt;</td>\n",
              "      <td>it's a bit good . &lt;end&gt;</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5a4b673d-4577-41f2-8ff1-929ad5ad919f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5a4b673d-4577-41f2-8ff1-929ad5ad919f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5a4b673d-4577-41f2-8ff1-929ad5ad919f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-bbb164e6-7d73-40a4-bb14-590332e1f258\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bbb164e6-7d73-40a4-bb14-590332e1f258')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-bbb164e6-7d73-40a4-bb14-590332e1f258 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"en\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"<start> be prepared . <end> \",\n          \"<start> i'm young , too . <end> \",\n          \"<start> tom wasn't rich . <end> \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ru\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"<start> \\u0431\\u0443\\u0434\\u044c\\u0442\\u0435 \\u0433\\u043e\\u0442\\u043e\\u0432\\u044b ! <end> \",\n          \"<start> \\u044f \\u0442\\u043e\\u0436\\u0435 \\u043c\\u043e\\u043b\\u043e\\u0434\\u043e\\u0439 . <end> \",\n          \"<start> \\u0442\\u043e\\u043c \\u043d\\u0435 \\u0431\\u044b\\u043b \\u0431\\u043e\\u0433\\u0430\\u0442 . <end> \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"en -> ru\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"\\u043e\\u043d\\u0438 \\u044d\\u0442\\u043e . <end> \",\n          \"\\u044f \\u043c\\u0435\\u043d\\u044f , \\u0447\\u0442\\u043e \\u0447\\u0442\\u043e \\u0447\\u0442\\u043e \\u0447\\u0442\\u043e \\u0447\\u0442\\u043e \\u0447\\u0442\\u043e \\u0447\\u0442\\u043e \\u0447\\u0442\\u043e \\u0447\\u0442\\u043e \",\n          \"\\u0442\\u044b \\u043d\\u0435 \\u043d\\u0435 \\u043d\\u0435 \\u043d\\u0435 \\u0447\\u0442\\u043e \\u0447\\u0442\\u043e \\u0447\\u0442\\u043e \\u0447\\u0442\\u043e \\u043f\\u043e\\u0436\\u0430\\u043b\\u0443\\u0439\\u0441\\u0442\\u0430 . <end> \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ru -> en\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"open the door . <end> \",\n          \"i was a bit shy . <end> \",\n          \"tom was very shy . <end> \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    }
  ]
}